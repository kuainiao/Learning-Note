## Hash索引
hash索引的整体思路是基于log的，写入数据时追加到log文件尾部，由于是顺序写，从而保证了效率
### 一.初级hash索引

![](images/1.jpg)


整体结构分为两个部分：索引和数据

**索引** :
- hash结构，存放在内存中，hash value为真实数据在log文件中的偏移

**数据** :
- 存放在磁盘文件上(log文件)，包含key对应的真实数据

读取时**根据数据偏移找到对应的value**；写入时直**接将新的数据append到log文件的尾部同时更新内存中的索引**。Bitcask的存储引擎采用了类似的思路

为了避免log文件越来越大(写入是不断append)，最后耗尽磁盘，**将大的log文件切分成固定大小的segment文件。在写入时，append到当前segment文件尾部，当segment文件增大到一定的大小时，关闭当前segment文件，同时创建一个新的segment文件，之后的写入append到新的segment文件尾部**。然后在这些segment文件上执行**compaction**操作，删除重复过时的，只保留最近最新的数据。下图展示了一个segment文件执行compaction操作，生成一个新的Compacted Segment文件

![](images/2.jpg)


在执行compaction的时候，可以同时对多个segment文件进行操作，并进行融合(merge)，生成一个结果文件

![](images/3.jpg)


**注意：** segment文件在写入之后是不会改变的，进行compaction并融合之后的结果会生成一个新文件，因此可以使用另外的线程在后台执行compaction，这不会影响在旧的segment文件上进行读写操作。当融合流程完成之后，读操作将切换到融合后的新文件，旧的segment文件就可以删掉了。

当存在多个segment文件时，每一个segment文件在内存中都有自己的hash索引，查找时，先在最新的segment文件中查找，如果没有找到，就去查找次新的segment文件，以此类推。因此上面的融合流程会减少segment文件数量，从而保证不用查找太多的hash索引


在实现上述流程时，有许多**重要的问题**需要考虑：
- 文件格式 ： 实现上通常使用二进制的格式，而不是这里展示的csv格式
- 删除记录 ： 如果我们要删除一行记录，通常需要append一个删除动作，在融合的时候，删除动作会告诉融合流程删掉对应的数据。
- 崩溃恢复 ： 如果数据库重启，会丢失内存中所有的索引结构，虽然可以通过所有的segment文件重建索引，但是当segment文件很大时，这个操作可能太耗时，Bitcask在磁盘上保存了每个segment文件的hash索引快照，从而加快了恢复过程
- 记录部分写 (Partially written records) : 当数据库在写入操作执行过程中崩溃，会导致部分写。Bitcask的文件包含了校验和，会发现这些坏掉的数据
- 并发控制 ：由于写入操作严格按照顺序写入，常见的方式是使用一个写线程。数据segment文件只能追加或者不变，因此可以多个读线程并发读

追加写log的方式看起来有些浪费，为什么不在原有的基础上直接覆盖了？
- 追加写和融合文件的方式比起随机写更加高效
- 并发控制和崩溃恢复更加简单，因为segment文件只会追加或者不变
- 融合旧的segment文件防止数据随着时间过分分散

上述hash索引的缺点：
- hash索引必须全部存放在内存中，如果key的数量太大，内存不够
- hash索引无法支持范围查找，比如查找kitty0000 到 kitty9999 之间的所有数据

### 二. SSTables和LSM-Trees
